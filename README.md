
# Welcome to Java Machine Learning Using Spark

Task: 
• Build all java needed classes (POJO , DAO, web service and a tester client for the web service)
• Make a web service to get the following from the data set:
1. Read data set and convert it to dataframe or Spark RDD and display some from it.
2. Display structure and summary of the data.
3. Clean the data (null, duplications)
4. Count the jobs for each company and display that in order (What are the most demanding companies for jobs?)
5. Show step 4 in a pie chart 
6. Find out What are it the most popular job titles? 
7. Show step 6 in bar chart 
8. Find out the most popular areas?
9. Show step 8 in bar chart 
10. Print skills one by one and how many each repeated and order the output to find out the most important skills required?
11. Factorize the YearsExp feature and convert it to numbers in new col. (Bounce )
12. Apply K-means for job title and companies (Bounce )

# Solution

* This project was made using:

    1- Spring Boot
    
    2- Apache Spark
  
## A Wuzzuf Machine learning File

Contains the source code.

Contains the Jobs csv file from Kaggle.

https://www.kaggle.com/omarhanyy/wuzzuf-jobs

## Libraries used:

* Apache Spark

* Spring Boot

* Thymeleaf

* Xchart

* SQL

The project also contains HTML, CSS, and JS to print all the output on a local host server.

## Client Side File

Contains Java code to construct a User interface to connect to the server side to display the output.
